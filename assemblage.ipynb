{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assemblage de la pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\n",
    "from typing import no_type_check\n",
    "import numpy as np \n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc \n",
    "import csv \n",
    "import os \n",
    "from tqdm import tqdm"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/53/knyk_r6x3tgb66xwzpl33bv40000gn/T/ipykernel_2090/2650795118.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mapping\n",
    "Cette fonction permet de récupérer uniquement les données pertinentes et présente en quantité suffisante pour être analysées "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "def get_pouls(df):\n",
    "    \"\"\"Fonction qui cree une série pouls à partir de df.FC préférentiellement, et sinon, df.Pouls\n",
    "    Args:\n",
    "        - df : pandas.DataFrame  -> df[\"FC\"]\n",
    "    Returns:\n",
    "        - pandas.Series\n",
    "    \"\"\"\n",
    "    serie_pouls  = df['FC']\n",
    "    serie_pouls[serie_pouls.isna()] = df['Pouls'].loc[serie_pouls.isna()]\n",
    "\n",
    "    return serie_pouls\n",
    "    \n",
    "def get_pression(df):\n",
    "    \"\"\"Fonction qui cree une série pression à partir de df['PAm'] préférentiellement, et sinon, df['PNIm'] et sinon, df['PBm']\n",
    "    Args:\n",
    "        - df : pandas.DataFrame  -> df['PAm']\n",
    "    Returns:\n",
    "        - pandas.Series\n",
    "    \"\"\"\n",
    "    serie_pression = df['PAm']\n",
    "    serie_pression[serie_pression.isna()] = df['PNIm'].loc[serie_pression.isna()]\n",
    "    serie_pression[serie_pression.isna()] = df['PBm'].loc[serie_pression.isna()]\n",
    "    \n",
    "    return serie_pression\n",
    "\n",
    "\n",
    "def get_temperature(df):\n",
    "    \"\"\"Fonction qui cree une série pression à partir de df['Temp'] préférentiellement, et sinon, df['Toeso'] et sinon, df['T1']\n",
    "    Args:\n",
    "        - df : pandas.DataFrame  -> df['Temp']\n",
    "    Returns:\n",
    "        - pandas.Series\n",
    "    \"\"\"\n",
    "    serie_temperature = df['Temp']\n",
    "    serie_temperature[serie_temperature.isna()] = df['Toeso'].loc[serie_temperature.isna()]\n",
    "    serie_temperature[serie_temperature.isna()] = df['T1'].loc[serie_temperature.isna()]\n",
    "\n",
    "    return serie_temperature\n",
    "\n",
    "def mapping_pas4(df, bloc_4 = False):\n",
    "    \"\"\"Fonction qui cree une nouvelle dataframe bien mappée avec les colonnes Pouls Pression SpO2  FR, et hors bloc 4, Temperature\n",
    "    La température au bloc 4 peut varier lors de refroidissements donc on ne la map pas\n",
    "    Args:\n",
    "        - df : pandas.DataFrame -> df[\"FC\"],df['PAm'],df['Temp'], etc..\n",
    "        - bool\n",
    "    Returns:\n",
    "        - pandas.DataFrame\"\"\"\n",
    "    df.replace('AP',np.NaN, inplace = True)\n",
    "    mapped_df = pd.DataFrame()\n",
    "    mapped_df[\"seconde\"] = df[\"seconde\"]\n",
    "    mapped_df[\"Pouls\"] = get_pouls(df)\n",
    "    mapped_df[\"Pression\"] = get_pression(df)\n",
    "    if not bloc_4:\n",
    "        mapped_df[\"Temperature\"] = get_temperature(df)\n",
    "        mapped_df[\"SpO2\"] = df[\"SpO2\"]\n",
    "        mapped_df[\"FR\"] = df[\"FR\"]\n",
    "    else :\n",
    "    #traitement du bloc 4\n",
    "        cols = df.columns\n",
    "        badliste = [\"FC\",\"Pouls\",\"PAm\", \"PNIm\", \"PBm\",'HEURE','DATE','LIT','NOM']\n",
    "        cols = cols.drop(badliste)\n",
    "        for col in cols:\n",
    "            mapped_df[col] = df[col]\n",
    "        \n",
    "    mapped_df.dropna(axis = 1, how = 'all')\n",
    "    \n",
    "    return mapped_df.astype(float)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Separation des patients\n",
    "\n",
    "Nous avons constaté que les fichiers contenaient chacuns plusieurs patients, l'idée est donc d'écrire un programme qui sépare les différents patients"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def column_test_patient(df):\n",
    "    '''\n",
    "    arg: df, DataFrame\n",
    "    return: DataSerie of meaningful Series\n",
    "    '''\n",
    "    serie_patient = df['Pouls']\n",
    "    serie_patient[serie_patient.isna()] = df['SpO2'].loc[serie_patient.isna()]\n",
    "    serie_patient[serie_patient.isna()] = df['Pression'].loc[serie_patient.isna()]\n",
    "    serie_patient[serie_patient.isna()] = df['FR'].loc[serie_patient.isna()]\n",
    "\n",
    "    return serie_patient\n",
    "\n",
    "\n",
    "def binar_list(df):\n",
    "    '''\n",
    "    arg: df, DataFrame\n",
    "    return: list of presence of data (with 0,1 mask)\n",
    "    '''\n",
    "    patient_serie=column_test_patient(df)\n",
    "    return patient_serie.notna().astype(int)\n",
    "\n",
    "\n",
    "def list_index_patients(binar_list):\n",
    "    '''\n",
    "    arg: binar_list of presence, list\n",
    "    return: list of tuple (key,length of sequence)\n",
    "    '''\n",
    "    return [\n",
    "        (key, len(list(group))) for key, group in itertools.groupby(binar_list)\n",
    "    ]\n",
    "\n",
    "\n",
    "            \n",
    "def noises_treatment(list_index_patient, threshold):\n",
    "    '''\n",
    "    arg: list of tuple (key,length of sequence), threshold (duration of bloc cleaning)\n",
    "    return: list of tuple (key,length of sequence) without noises\n",
    "    '''\n",
    "    nouveau_index=[list_index_patient[0]]\n",
    "    i=1\n",
    "    while i <(len(list_index_patient)-1):\n",
    "        if list_index_patient[i][1]<threshold:\n",
    "            last_el = list(nouveau_index[-1])\n",
    "            last_el[1]+=list_index_patient[i][1]\n",
    "            last_el[1]+=list_index_patient[i+1][1]\n",
    "            nouveau_index[-1]=tuple(last_el)\n",
    "            i+=1\n",
    "        else :\n",
    "            nouveau_index.append(list_index_patient[i])\n",
    "        i+=1\n",
    "    if list_index_patient[-1][1]>=threshold :\n",
    "        nouveau_index.append(list_index_patient[-1])\n",
    "    else : \n",
    "        last_el = list(nouveau_index[-1])\n",
    "        last_el[1]+=list_index_patient[-1][1]\n",
    "        nouveau_index[-1]=tuple(last_el)\n",
    "    return nouveau_index\n",
    "\n",
    "def accumulate_list(list_len):\n",
    "    return [0]+list(itertools.accumulate(list_len))\n",
    "\n",
    "def break_finder(list_index_patients,threshold):\n",
    "    '''\n",
    "    arg: list of tuple (key,length of sequence) without noises\n",
    "    return: list of list [begin,end] which limits index of cleaning\n",
    "    '''\n",
    "    list_len=[len1[1] for len1 in list_index_patients]\n",
    "    accumulate_list1=accumulate_list(list_len)\n",
    "    breaks=[]\n",
    "    for index,len1 in enumerate(list_index_patients):\n",
    "        value , length = len1\n",
    "        begin , end = accumulate_list1[index] , accumulate_list1[index+1]\n",
    "        if (value == 0) and (length > threshold):\n",
    "            breaks.append([begin,end])\n",
    "    return breaks\n",
    "\n",
    "\n",
    "\n",
    "def list_to_patients(list_break,df):\n",
    "    \"\"\"d'une liste de listes debut/fin des pauses au bloc et de la dataframe associée renvoie la liste de dataframe patients \n",
    "    Args:\n",
    "        - liste: list\n",
    "        - df: pd.DataFrame\n",
    "    Return\n",
    "        patients: list de pd.Dataframe\"\"\"\n",
    "    patients=[df[list_break[i][1]:list_break[i+1][0]] for i in range (-1,len(list_break)-1)] #On commence à -1 pour réserver une case pour le potentiel premier patient\n",
    "    if list_break:\n",
    "        patients[0]=df[0:list_break[0][0]]\n",
    "        patients.append(df[list_break[-1][1]:-1])\n",
    "    return patients\n",
    "\n",
    "\n",
    "def separation_patients(df,threshold):\n",
    "    '''\n",
    "    arg: df, Dataframe ; threshold (duration of bloc cleaning)\n",
    "    returns: list of patients' DataFrames\n",
    "    '''\n",
    "    list_index_patients1=list_index_patients(binar_list(df))\n",
    "    list_index_pat_treated=noises_treatment(list_index_patients1, threshold)\n",
    "    breaks=break_finder(list_index_pat_treated,threshold)\n",
    "\n",
    "    return list_to_patients(breaks,df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Nettoyage\n",
    "\n",
    "Nous avons besoin de quelques fonctions qui écartent les fichiers csv vides et les patients vides"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def second(df):\n",
    "    \"\"\"renvoie une serie contenant le temps en seconde à partir de la colonne HEURE\n",
    "\n",
    "    Args: \n",
    "        - df: pandas.DataFrame -> df contient les dates en heures \n",
    "    Return: \n",
    "        - pandas.Series \"\"\"\n",
    "    delta_serie = pd.to_datetime(df.HEURE) - pd.to_datetime(df.HEURE[0])\n",
    "    delta_serie = delta_serie.apply(lambda delta : delta.total_seconds())\n",
    "    \n",
    "    while (delta_serie<0).any() :\n",
    "        delta_serie.loc[delta_serie<0]+= 60*24*60\n",
    "    \n",
    "    return delta_serie\n",
    "\n",
    "def df_is_empty(df):\n",
    "    '''\n",
    "    Args : \n",
    "        - df : Pandas.DataFrame\n",
    "    Returns\n",
    "        - bool \n",
    "    Renvoie True si la dataframe is empty, false sinon\n",
    "    '''\n",
    "    return len(df) < 5\n",
    "\n",
    "def time_is_missing(df):\n",
    "    '''\n",
    "    Args : \n",
    "        - df : Pandas.DataFrame\n",
    "    Returns\n",
    "        - bool \n",
    "    Renvoie True si la dataframe ne contient pas de colonne 'HEURE'\n",
    "    '''\n",
    "    return 'HEURE' not in df.columns\n",
    "\n",
    "def patient_is_empty(patient):\n",
    "    '''\n",
    "    Args : \n",
    "        - patient = Pandas.DataFrame\n",
    "    Returns : \n",
    "        - bool \n",
    "    Retourne True si l'opération dure moins de 20 minutes\n",
    "    '''\n",
    "    return len(patient)<4*60"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### De l'ordre \n",
    "\n",
    "Pour rendre le traitement des données plus agréable, nous avons trié les fichiers par blocs puis par dates "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def sort_folder(folder):\n",
    "    \"\"\"prend le fichier data_brutes en arguments ( on celui avec les fichiers NaN enlevés ) \n",
    "    et renvoi un dictionnaire avec en clef le nom des blocs et en valeur une liste triée par date croissante \n",
    "    des csv des blocs\n",
    "    Args :\n",
    "        - folder : str ( nom du dossier)\n",
    "    Return :\n",
    "        - dic : dict \"\"\"\n",
    "    sorted_list = []\n",
    "    dic = {}\n",
    "    for filename in os.listdir(folder) :\n",
    "        sorted_list.append((filename[0:7] + filename[-8:-4] + filename[-12:-10], filename))\n",
    "    sorted_list.sort()\n",
    "    \n",
    "    for string, filename in sorted_list : \n",
    "        if filename[0:6] in dic.keys():\n",
    "            \n",
    "            dic[filename[0:6]].append(filename)\n",
    "        else:\n",
    "            dic[filename[0:6]]=[filename]\n",
    "    return dic"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pipeline\n",
    "\n",
    "Il est maintenant temps de tout assembler pour écrire le programme qui va écrire les fichiers .csv patients "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dans un premier temps, nous implémentons un dictionnaire qui associe à chaque bloc une durée minimale d'absence de données à partir de laquelle il faut considérer que le patient a été changé. \n",
    "Par exemple le bloc_1 ne traite qiue des petites chirurgies d'urgences, qui ne nécesite pas forcément un temps de transfert très long. Nous avons donc décidé d'abaisser le temps de battement à seulement 15 minutes. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "thresholds = {\n",
    "        'bloc_1':15*60//5,\n",
    "        'bloc_2':20*60//5,\n",
    "        'bloc_3':20*60//5,\n",
    "        'bloc_4':20*60//5,\n",
    "        'bloc_5':20*60//5,\n",
    "        'bloc_6':20*60//5,\n",
    "        'bloc_7':20*60//5,\n",
    "        'bloc_8':20*60//5,\n",
    "        'Bloc_1':15*60//5,\n",
    "        'Bloc_2':20*60//5,\n",
    "        'Bloc_3':20*60//5,\n",
    "        'Bloc_4':20*60//5,\n",
    "        'Bloc_5':20*60//5,\n",
    "        'Bloc_6':20*60//5,\n",
    "        'Bloc_7':20*60//5,\n",
    "        'Bloc_8':20*60//5\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def processing(folder):\n",
    "    dic = sort_folder(folder)\n",
    "    for bloc,filelist in dic.items():\n",
    "        for filename in tqdm(filelist, desc = bloc):\n",
    "            df = pd.read_csv(f\"{folder}/{filename}\", encoding = 'latin-1')\n",
    "            if df_is_empty(df) or time_is_missing(df):\n",
    "                continue\n",
    "            df['seconde'] = second(df)\n",
    "            df = mapping_pas4(df, bloc_4 = (bloc == \"bloc_4\"))\n",
    "            for i,patient in enumerate(separation_patients(df,thresholds[bloc])):\n",
    "                patient_name = filename.replace(\".csv\",f\"_{i}.csv\")\n",
    "                patient_filename = \"patients/\" + patient_name\n",
    "                if patient_is_empty(patient):\n",
    "                    continue\n",
    "                patient.to_csv(patient_filename)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "On peut maintenant appliquer le pipeline à un dossier de fichiers csv. Cette pipeline va alors écrire des fichiers .csv des dans un dossier \"patients\" qu'il faut d'abord créer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "processing(\"Données\")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'sort_folder' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/53/knyk_r6x3tgb66xwzpl33bv40000gn/T/ipykernel_2090/2544534809.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Données\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/53/knyk_r6x3tgb66xwzpl33bv40000gn/T/ipykernel_2090/1488807145.py\u001b[0m in \u001b[0;36mprocessing\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbloc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilelist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{folder}/{filename}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sort_folder' is not defined"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "569d6b7e9215e11aba41c6454007e5c1b78bad7df09dab765d8cf00362c40f03"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}